Day 15

Task 1
#
# Assignment 1: Implement a Bagging Regressor Using PyTorch
# Dataset: Diabetes Dataset
#
# Objective: Implement a Bagging regressor to predict diabetes progression using the Diabetes dataset. Evaluate the model using various regression metrics (MAE, MSE, RMSE, R-squared).
#
# Steps:
#
# Load the Diabetes dataset:
# Use sklearn.datasets.load_diabetes to load the dataset.
#
# Preprocess the data:
# Normalize the features using StandardScaler.
#
# Define the model:
# Create a simple linear regression model using PyTorch.
#
# Implement Bagging:
# Use sklearn.ensemble.BaggingRegressor to implement the Bagging ensemble method.
# Train multiple models on different subsets of the training data.
#
# Evaluate the model:
# Calculate and interpret regression metrics (MAE, MSE, RMSE, R-squared) on the test set.


from sklearn.datasets import load_diabetes
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import torch
import torch.nn as nn
import numpy as np

# Step 1: Load the Diabetes dataset
data = load_diabetes()
X, y = data.data, data.target

# Step 2: Preprocess the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Convert data to PyTorch tensors
X_train_tensor = torch.from_numpy(X_train).float()
y_train_tensor = torch.from_numpy(y_train).float().view(-1, 1)
X_test_tensor = torch.from_numpy(X_test).float()
y_test_tensor = torch.from_numpy(y_test).float().view(-1, 1)

# Step 3: Define the base model in PyTorch
class LinearRegressionModel(nn.Module):
    def __init__(self, input_size, output_size):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(input_size, output_size)

    def forward(self, x):
        return self.linear(x)

# Step 4: Implement Bagging using BaggingRegressor
base_model = LinearRegressionModel(X_train.shape[1], 1)
bagging_model = BaggingRegressor(n_estimators=10, random_state=42)

# Fit the Bagging model
bagging_model.fit(X_train, y_train)

# Predict on the test set
y_pred = bagging_model.predict(X_test)

# Step 5: Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"R-squared (R2): {r2:.4f}")




# Assignment 2: Implement a Gradient Boosting Regressor Using PyTorch
# Dataset: Any Housing Dataset
#
# Objective: Implement a Gradient Boosting regressor to predict housing prices using the  Housing dataset. Evaluate the model using various regression metrics (MAE, MSE, RMSE, R-squared).
#
# Steps:
# Load the Housing dataset:
#
# Preprocess the data:
# Normalize the features using StandardScaler.
#
# Define the model:
# Create a simple linear regression model using PyTorch.
#
# Implement Gradient Boosting:
# Use sklearn.ensemble.GradientBoostingRegressor to implement the Gradient Boosting ensemble method.
# Train the model on the training data.
#
# Evaluate the model:
# Calculate and interpret regression metrics (MAE, MSE, RMSE, R-squared) on the test set.


import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Step 1: Load the Housing dataset
housing_data = fetch_california_housing()

# Step 2: Preprocess the data
X = housing_data.data
y= housing_data.target

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Step 3: Implement Gradient Boosting using GradientBoostingRegressor
gb_regressor = GradientBoostingRegressor(random_state=42)

# Train the model on the training data
gb_regressor.fit(X_train, y_train)

# Predict on the test set
y_pred = gb_regressor.predict(X_test)

# Step 4: Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
print(f"R-squared (R2): {r2:.4f}")



==================================================================================


Day 16

# question 1:
#
# Install PyTorch and set up the environment.
# Build a simple neural network with one hidden layer using PyTorch.
# Implement forward propagation for the neural network.
# Print the architecture and output of the network for a given input tensor.
#
# Implement a method to monitor the training progress by plotting the loss curve.
# Experiment with different learning rates and batch sizes to improve the performance of the neural network.
# Implement an early stopping mechanism to halt training when the validation loss stops improving.

import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt


# Define the neural network class
class SimpleNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out


# Define the architecture
input_size = 3  # Example input size
hidden_size = 5  # Number of hidden units
output_size = 2  # Example output size
model = SimpleNN(input_size, hidden_size, output_size)

# Print the model architecture
print(model)

# Example input tensor
input_tensor = torch.randn((1, input_size))
output = model(input_tensor)
print(f"Input tensor: {input_tensor}")
print(f"Output tensor: {output}")

# Dummy dataset
X = torch.randn((100, input_size))
y = torch.randn((100, output_size))

# Loss and optimizer
criterion = nn.MSELoss()
learning_rate = 0.01
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training loop with early stopping
num_epochs = 100
losses = []
patience = 10
best_loss = None
patience_counter = 0

for epoch in range(num_epochs):
    # Forward pass
    outputs = model(X)
    loss = criterion(outputs, y)

    # Backward pass and optimization
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    losses.append(loss.item())

    # Check for early stopping
    if best_loss is None or loss < best_loss:
        best_loss = loss
        patience_counter = 0
    else:
        patience_counter += 1

    if patience_counter >= patience:
        print(f"Early stopping at epoch {epoch + 1}")
        break

    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

# Plot the loss curve
plt.plot(losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Curve')
plt.show()




# Question 2:
#
# Extend the simple neural network to include a backward propagation method.
# Use a loss function and optimizer to train the neural network on a sample dataset.
# Implement the training loop and monitor the loss during training.
#
# Train the neural network on a real dataset (e.g., CIFAR-10).
# Implement evaluation metrics to monitor the performance of the network.
# Save and load the trained model.

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import torch.nn.functional as F

# Transformations to apply to the images
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


# Define the neural network class
class CIFAR10NN(nn.Module):
    def __init__(self):
        super(CIFAR10NN, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


# Training loop with loss monitoring
def train_model(model, trainloader, criterion, optimizer, num_epochs=10):
    model.train()
    losses = []

    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            # Print statistics
            running_loss += loss.item()
            if i % 100 == 99:  # Print every 100 mini-batches
                print(f'[Epoch {epoch + 1}, Mini-batch {i + 1}] Loss: {running_loss / 100:.3f}')
                running_loss = 0.0

        losses.append(running_loss / len(trainloader))

    print('Finished Training')
    return losses


# Evaluation function
def evaluate_model(model, testloader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')
    return accuracy


def main():
    # Load CIFAR-10 dataset
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)

    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

    # Initialize model, loss function, and optimizer
    model = CIFAR10NN()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    num_epochs = 10
    losses = train_model(model, trainloader, criterion, optimizer, num_epochs)

    # Plot the loss curve
    plt.plot(losses)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Loss Curve')
    plt.show()

    # Evaluate the model
    accuracy = evaluate_model(model, testloader)

    # Save the model
    torch.save(model.state_dict(), 'cifar10_model.pth')
    print('Model saved')

    # Load the model
    loaded_model = CIFAR10NN()
    loaded_model.load_state_dict(torch.load('cifar10_model.pth'))
    print('Model loaded')


if __name__ == '__main__':
    main()


================================================================================



Day 17



Download Housing dataset from kaggle
#
# Assignment Question: Building and Evaluating a Neural Network for Housing Price Prediction
#
# Tasked with building a neural network model to predict housing prices based on a dataset provided.
#
# Dataset Description:
# Dataset containing various features of houses (e.g., number of bedrooms, size of the house, location, etc.) and their corresponding prices.
#
# Model Building:
#
# Neural Network Architecture: Design a neural network architecture using PyTorch with the following specifications:
# Input layer that matches the number of features in the dataset.
# At least two hidden layers with advanced activation functions such as Leaky ReLU or ELU.
# Output layer for predicting the house price.
#
# Regularization Techniques: Implement at least two regularization techniques:
# L1.or L2 regularization
# Apply dropout regularization to one of the hidden layers.
#
# Training and Optimization:
# Optimization Algorithms: Train your neural network using the following optimization algorithms:
# Adam
# SGD with momentum
# Compare their performance in terms of convergence speed and final prediction accuracy.
#
# Evaluation:
# Performance Metrics: Evaluate your trained model using appropriate metrics such as Mean Squared Error (MSE) or R-squared score.
# Visualization: Visualize the predicted house prices against the actual prices to understand the model's predictive capabilities.
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('Housing.csv')

# Separate features and target variable
X = data.drop(columns=['price'])
y = data['price']

# Identify categorical and numerical columns
categorical_cols = X.select_dtypes(include=['object']).columns
numerical_cols = X.select_dtypes(include=['number']).columns

# Preprocessing for numerical data
numerical_transformer = StandardScaler()

# Preprocessing for categorical data
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Preprocess the data
X = preprocessor.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Define the Neural Network Architecture
class HousingPriceNN(nn.Module):
    def __init__(self, input_size):
        super(HousingPriceNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.dropout = nn.Dropout(0.5)
        self.leaky_relu = nn.LeakyReLU()
        self.elu = nn.ELU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.leaky_relu(x)
        x = self.fc2(x)
        x = self.elu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        return x


# Initialize the model
input_size = X_train.shape[1]
model = HousingPriceNN(input_size)

# Define loss function
criterion = nn.MSELoss()

# Define optimizers
optimizer_adam = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)  # L2 regularization
optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.01)  # L2 regularization


# Train the model
def train_model(model, optimizer, num_epochs=100):
    for epoch in range(num_epochs):
        model.train()
        inputs = torch.tensor(X_train, dtype=torch.float32)
        targets = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)

        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, targets)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')


# Train with Adam optimizer
print("Training with Adam optimizer")
train_model(model, optimizer_adam)

# Reinitialize the model for SGD training
model = HousingPriceNN(input_size)

# Train with SGD optimizer
print("Training with SGD optimizer")
train_model(model, optimizer_sgd)


# Evaluate the model
def evaluate_model(model):
    model.eval()
    inputs = torch.tensor(X_test, dtype=torch.float32)
    targets = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)

    with torch.no_grad():
        predictions = model(inputs)
        mse = mean_squared_error(targets.numpy(), predictions.numpy())
        r2 = r2_score(targets.numpy(), predictions.numpy())

    return mse, r2


# Evaluate the model trained with Adam optimizer
mse_adam, r2_adam = evaluate_model(model)
print(f'Adam Optimizer - MSE: {mse_adam:.4f}, R-squared: {r2_adam:.4f}')

# Evaluate the model trained with SGD optimizer
model = HousingPriceNN(input_size)
mse_sgd, r2_sgd = evaluate_model(model)
print(f'SGD Optimizer - MSE: {mse_sgd:.4f}, R-squared: {r2_sgd:.4f}')


# Visualize the results
def plot_predictions(model, title):
    model.eval()
    inputs = torch.tensor(X_test, dtype=torch.float32)
    targets = y_test.values

    with torch.no_grad():
        predictions = model(inputs).numpy()

    plt.figure(figsize=(10, 6))
    plt.scatter(targets, predictions, alpha=0.6)
    plt.plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--', lw=2)
    plt.xlabel('Actual Prices')
    plt.ylabel('Predicted Prices')
    plt.title(title)
    plt.show()


# Plot predictions for the model trained with Adam optimizer
plot_predictions(model, 'Actual vs Predicted Prices (Adam Optimizer)')

# Plot predictions for the model trained with SGD optimizer
plot_predictions(model, 'Actual vs Predicted Prices (SGD Optimizer)')




========================================================================================================




Day 18



download dog vc cat dataset from kaggle



# Assignment Question: Cat vs Dog Image Classifier
#
# Tasked with building a Convolutional Neural Network (Day18 - CNN) to classify images of cats and dogs using the "Dogs vs Cats" dataset from Kaggle.
#
# Dataset Description:
# Download the "Dogs vs Cats" dataset from Kaggle, which contains thousands of images of cats and dogs.
# Split the dataset into training and validation sets.
#
# Model Building:
# Day18 - CNN Architecture: Design a Day18 - CNN architecture in PyTorch for image classification. Include convolutional layers, pooling layers, and fully connected layers.
# Use ReLU activations and implement dropout for regularization.
#
# Data Augmentation:
# Implement data augmentation techniques such as random rotations, flips, and resizing using PyTorch's transforms.
#
# Training and Optimization:
# Train your Day18 - CNN using appropriate optimization algorithms (e.g., Adam).
# Monitor training progress and adjust hyperparameters if necessary.
#
# Evaluation:
# Evaluate the trained model on the validation set using accuracy as the metric.
# Visualize the model's predictions on a few sample images from the validation set.
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
import torch.nn.functional as F
import PIL

# Custom dataset class to handle corrupted images
class CustomImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        try:
            return super(CustomImageFolder, self).__getitem__(index)
        except (PIL.UnidentifiedImageError, OSError, ValueError) as e:
            print(f"Skipping corrupted image: {self.imgs[index][0]}")
            return self.__getitem__((index + 1) % len(self.imgs))

# Define the CustomCNN architecture
class CustomCNN(nn.Module):
    def __init__(self):
        super(CustomCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(64 * 56 * 56, 512)  # Assuming input size is 224x224
        self.fc2 = nn.Linear(512, 2)  # Cat and Dog classes

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 56 * 56)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Function to train the model
def train_model(net, trainloader, criterion, optimizer, num_epochs=10):
    net.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if i % 100 == 99:  # Print every 100 mini-batches
                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / 100:.4f}')
                running_loss = 0.0
    print('Finished Training')

# Function to evaluate the model
def evaluate_model(net, testloader):
    net.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    print(f'Accuracy of the network on the test images: {accuracy:.2f}%')
    return accuracy

if __name__ == '__main__':
    # Data transformations
    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    # Load the dataset
    data_dir = './kagglecatsanddogs_5340/PetImages'
    full_dataset = CustomImageFolder(root=data_dir, transform=data_transforms['train'])

    # Split dataset into training and validation sets
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    # Update the transforms for the validation dataset
    val_dataset.dataset.transform = data_transforms['val']

    # Create DataLoader objects
    dataloaders = {
        'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),
        'val': DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)
    }

    # Define the device
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # Initialize the model, criterion, and optimizer
    net = CustomCNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=0.001)

    # Train the model
    train_model(net, dataloaders['train'], criterion, optimizer, num_epochs=10)

    # Evaluate the model
    test_accuracy = evaluate_model(net, dataloaders['val'])



